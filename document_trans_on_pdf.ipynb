{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tutorial-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.pdfgen.canvas import Canvas\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import reportlab.pdfgen.canvas\n",
    "from reportlab.lib.units import mm\n",
    "\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.platypus import  SimpleDocTemplate\n",
    "from reportlab.lib.units import mm, inch\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.lib.styles import ParagraphStyle, getSampleStyleSheet\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from PyPDF2 import PdfFileMerger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hispanic-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import Paragraph, Frame\n",
    "from reportlab.lib.colors import Color, black, blue, red\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "addressed-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.styles import (ParagraphStyle, getSampleStyleSheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "outdoor-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "import six\n",
    "from google.cloud import translate_v2 as translate\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import uuid\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fluid-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureType(Enum):\n",
    "    PAGE = 1\n",
    "    BLOCK = 2\n",
    "    PARA = 3\n",
    "    WORD = 4\n",
    "    SYMBOL = 5\n",
    "    \n",
    "def get_document_bounds(document, feature):\n",
    "    bounds=[]\n",
    "    for i,page in enumerate(document.pages):\n",
    "        for block in page.blocks:\n",
    "            if feature==FeatureType.BLOCK:\n",
    "                bounds.append(block.bounding_box)\n",
    "            for paragraph in block.paragraphs:\n",
    "                if feature==FeatureType.PARA:\n",
    "                    bounds.append(paragraph.bounding_box)\n",
    "                for word in paragraph.words:\n",
    "                    for symbol in word.symbols:\n",
    "                        if (feature == FeatureType.SYMBOL):\n",
    "                            bounds.append(symbol.bounding_box)\n",
    "                    if (feature == FeatureType.WORD):\n",
    "                        bounds.append(word.bounding_box)\n",
    "    return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "improving-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_word(word):\n",
    "    assembled_word=\"\"\n",
    "    for symbol in word.symbols:\n",
    "        assembled_word+=symbol.text\n",
    "    return assembled_word\n",
    "\n",
    "def get_paragraph_level_text(document):\n",
    "    bounds=[]\n",
    "    Text = []  \n",
    "    for page in document.pages:\n",
    "        for block in page.blocks:\n",
    "            B = []\n",
    "            for paragraph in block.paragraphs:\n",
    "                P = []\n",
    "                for word in paragraph.words:\n",
    "                    assembled_word=assemble_word(word)\n",
    "                    P.append(assembled_word)\n",
    "                Text.append(\" \".join(P))\n",
    "    return Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "delayed-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_text_wrap(text,font,writing,max_width,max_height):\n",
    "    lines = [[]]\n",
    "    words = list(text)\n",
    "    for word in words:\n",
    "        # try putting this word in last line then measure\n",
    "        lines[-1].append(word)\n",
    "        (w,h) = writing.multiline_textsize('\\n'.join([' '.join(line) for line in lines]), font=font)\n",
    "        if w > max_width: # too wide\n",
    "            # take it back out, put it on the next line, then measure again\n",
    "            lines.append([lines[-1].pop()])\n",
    "            (w,h) = writing.multiline_textsize('\\n'.join([' '.join(line) for line in lines]), font=font)\n",
    "    return '\\n'.join([' '.join(line) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "julian-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_wrap_for_pdf(text,writing,max_width,max_height):\n",
    "    lines = [[]]\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        # try putting this word in last line then measure\n",
    "        lines[-1].append(word)\n",
    "        (w,h) = writing.multiline_textsize('\\n'.join([' '.join(line) for line in lines]))\n",
    "        if w > max_width: # too wide\n",
    "            # take it back out, put it on the next line, then measure again\n",
    "            lines.append([lines[-1].pop()])\n",
    "            (w,h) = writing.multiline_textsize('\\n'.join([' '.join(line) for line in lines]))\n",
    "    return '\\n'.join([' '.join(line) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "measured-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_wrap(text,font,writing,max_width,max_height):\n",
    "    lines = [[]]\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        # try putting this word in last line then measure\n",
    "        lines[-1].append(word)\n",
    "        (w,h) = writing.multiline_textsize('\\n'.join([' '.join(line) for line in lines]), font=font)\n",
    "        if w > max_width: # too wide\n",
    "            # take it back out, put it on the next line, then measure again\n",
    "            lines.append([lines[-1].pop()])\n",
    "            (w,h) = writing.multiline_textsize('\\n'.join([' '.join(line) for line in lines]), font=font)\n",
    "    return '\\n'.join([' '.join(line) for line in lines])\n",
    "\n",
    "def get_bounding_box_info(bound):\n",
    "    x0, y0 = bound.vertices[0].x, bound.vertices[0].y\n",
    "    x1, y1 = bound.vertices[1].x, bound.vertices[1].y\n",
    "    x2, y2 = bound.vertices[2].x, bound.vertices[2].y\n",
    "    x3, y3 = bound.vertices[3].x, bound.vertices[3].y\n",
    "    \n",
    "    # write text from coordinates x3, y3\n",
    "    # get max width and max height for text_wrap function..\n",
    "    max_width = (x1-x0)\n",
    "    max_height = (y3-y0)\n",
    "    \n",
    "#     print(max_width, max_height)\n",
    "    return x0, y0, max_width, max_height\n",
    "\n",
    "def fill_bounding_box(bound):\n",
    "    x0, y0 = bound.vertices[0].x, bound.vertices[0].y\n",
    "    x1, y1 = bound.vertices[1].x, bound.vertices[1].y\n",
    "    x2, y2 = bound.vertices[2].x, bound.vertices[2].y\n",
    "    x3, y3 = bound.vertices[3].x, bound.vertices[3].y\n",
    "    \n",
    "    return x0, y0, x2, y2\n",
    "\n",
    "def translate_text(target, text):\n",
    "    \"\"\"Translates text into the target language.\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # Text can also be a sequence of strings, in which cas\"e this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, target_language=target)\n",
    "    \n",
    "    translated_text = result[\"translatedText\"]\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bored-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path = \"ExecutiveOrder-2020-32.pdf\"\n",
    "folder_name = \"images\"\n",
    "pdf_folder_name = \"./pdfsss/\"\n",
    "pages = convert_from_path(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "novel-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:04<00:00,  5.33s/it]\n"
     ]
    }
   ],
   "source": [
    "Target = {'Hindi': 'hi','Chinese':'zh-CN', 'Arabic':'ar','Polish':'pl', 'Spanish':'es', 'Tagalog':'tl'}\n",
    "target = 'Tagalog'\n",
    "font = {\n",
    "        'Hindi':'ARIALUNI.TTF',\n",
    "        'Chinese':'ARIALUNI.TTF',\n",
    "        'Arabic':'ARIALUNI.TTF',\n",
    "        'Polish':'ARIALUNI.TTF',\n",
    "        'Spanish':'ARIALUNI.TTF',\n",
    "        'Tagalog':'ARIALUNI.TTF'\n",
    "        }\n",
    "\n",
    "\n",
    "merger = PdfFileMerger()\n",
    "\n",
    "for i in tqdm(range(len(pages))):\n",
    "    image_file = 'page_'+str(i)+'.jpg'\n",
    "    pages[i].save(os.path.join(folder_name, image_file))\n",
    "\n",
    "    # Calling google cloud vision API (text detection) \n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image_path = os.path.join(folder_name, image_file)\n",
    "\n",
    "    with io.open(image_path, 'rb') as image_file1:\n",
    "        content = image_file1.read()\n",
    "        content_image = types.Image(content=content)\n",
    "        response = client.document_text_detection(image=content_image)\n",
    "        document = response.full_text_annotation\n",
    "\n",
    "        # Getting the bounds and text\n",
    "        bounds = get_document_bounds(document, FeatureType.PARA)\n",
    "        TEXT = get_paragraph_level_text(document)\n",
    "        \n",
    "#         bg = Image.open(image_path)\n",
    "#         writing = ImageDraw.Draw(bg)\n",
    "        \n",
    "        pagesize = (600*mm, 800*mm)\n",
    "        pdf_file = 'page_'+str(i)+'.pdf'\n",
    "        pdf_path = os.path.join(pdf_folder_name, pdf_file)\n",
    "        pdf8 = canvas.Canvas(pdf_path , pagesize=pagesize, bottomup = 0)\n",
    "#         LOAD PDF USING CANVAS THE ORIGINAL PDF...................................................................\n",
    "        \n",
    "        for i in range(len(bounds)):\n",
    "            text_x, text_y, max_width, max_height = get_bounding_box_info(bounds[i])\n",
    "            x0, y0, x2, y2 = fill_bounding_box(bounds[i])\n",
    "            \n",
    "            area = max_width*max_height\n",
    "            text_ratio = area/ (len(TEXT[i]))\n",
    "            font_size = 22\n",
    "            if(text_ratio > 1500 and text_ratio <= 3000):\n",
    "                font_size = 25\n",
    "            elif(text_ratio > 3000 and text_ratio <= 6000):\n",
    "                font_size = 30\n",
    "            elif(text_ratio > 6000 and text_ratio <= 10000):\n",
    "                font_size = 35\n",
    "            elif(text_ratio > 10000):\n",
    "                font_size = 35\n",
    "                \n",
    "                \n",
    "#             pdf8.rect(text_x, text_y, max_width, max_height, stroke = 1, fill = 0)\n",
    "#             pdf8.setFont(\"Helvetica\",font_size)\n",
    "        \n",
    "            description = translate_text(Target[target], TEXT[i])\n",
    "            pdfmetrics.registerFont(TTFont('font_forall_text', 'ARIALUNI.TTF'))\n",
    "            \n",
    "            style = getSampleStyleSheet()\n",
    "\n",
    "\n",
    "            fiddle_style = ParagraphStyle('fiddle_style',\n",
    "                           fontName=\"font_forall_text\",\n",
    "#                            backColor = '#FFFF00',\n",
    "                           alignment = 0,\n",
    "                           allowOrphans = 0,\n",
    "                           allowWidows = 0,\n",
    "#                            borderColor = '#000000',\n",
    "                           borderPadding = 0,\n",
    "                           borderRadius = None,\n",
    "                           borderWidth = 1,\n",
    "                           bulletAnchor = 'start',\n",
    "                           bulletFontName = 'Helvetica',\n",
    "                           bulletFontSize = 10,\n",
    "                           bulletIndent = 0,\n",
    "                           embeddedHyphenation = 0,\n",
    "                           endDots = None,\n",
    "                           firstLineIndent = 0,\n",
    "                           fontSize = 25,\n",
    "                           justifyBreaks = 0,\n",
    "                           justifyLastLine = 0,\n",
    "                           leading = 26,\n",
    "                           leftIndent = 0,\n",
    "                           linkUnderline = 0,\n",
    "                           rightIndent = 20,\n",
    "                           spaceAfter = 0,\n",
    "                           spaceBefore = 0,\n",
    "                           spaceShrinkage = 0.05,\n",
    "                           splitLongWords = 1,\n",
    "                           strikeGap = 1,\n",
    "                           strikeOffset = 0.25,\n",
    "                           strikeWidth =1,\n",
    "                           textColor = Color(0,0,0,1),\n",
    "                           textTransform = None,\n",
    "                           underlineGap = 1,\n",
    "                           underlineOffset = -0.125,\n",
    "                           underlineWidth =1,\n",
    "                           uriWasteReduce = 0,\n",
    "                           wordWrap = None\n",
    "#                            parent=styles['Heading2'],\n",
    "                           )\n",
    "\n",
    "        \n",
    "            ptext = TEXT[i]\n",
    "            \n",
    "            p = Paragraph(ptext, fiddle_style)\n",
    "            p.wrapOn(pdf8, max_width, max_height)  # size of 'textbox' for linebreaks etc.\n",
    "            p.drawOn(pdf8, text_x, text_y)\n",
    "#             desc_font = ImageFont.truetype(font=font[target], size=font_size)\n",
    "#             description_wrapped = text_wrap_for_pdf(description,writing,max_width,max_height)\n",
    "            \n",
    "#             text_wrap_pdf(max_width,max_height,P, Canv)\n",
    "            \n",
    "#             description_wrapped = text_wrap_for_pdf(TEXT[i],writing,max_width,max_height)\n",
    "            \n",
    "#             pdf8.drawString(text_x, text_y, description_wrapped)\n",
    "        pdf8.save()\n",
    "#         get_updated_pdf(pdf8)\n",
    "#         merger = PdfFileMerger()\n",
    "        merger.append(pdf_path)\n",
    "\n",
    "merger.write(\"./result_1.pdf\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-arrangement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
